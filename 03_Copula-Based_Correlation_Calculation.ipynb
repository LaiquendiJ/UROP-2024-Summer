{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Correlation Using Discrete Copulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from scipy.stats import truncnorm, norm, multivariate_normal, nbinom\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tools as tl\n",
    "\n",
    "# load data\n",
    "data1_4 = pd.read_csv(\"mt-datasets/Donor1_CD4_Genes.csv\")\n",
    "# normalization\n",
    "data_norm = tl.RPM(data1_4)\n",
    "fitted_para = pd.read_csv('fitted_data/fitted_para.csv')\n",
    "\n",
    "\n",
    "data_pro = data_norm[fitted_para.columns.to_list()]\n",
    "data_pro = data_pro.reset_index(drop=True)\n",
    "N = data_pro.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the correlation between two datasets, the usual approach is to assume a bivariate normal distribution. However, this assumption may not always be appropriate. For our data, as observed in the previous section, the datasets themselves are not normally distributed. This implies that the bivariate normal model is not suitable, as it also assumes that each marginal distribution is normally distributed.\n",
    "We introduce a new method called Copula. This approach allows us to leverage the simulated marginal distributions for each dataset that we have already obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Copula\n",
    "To introduce Copula, we first need to present a key theorem known as Sklar's Theorem.\n",
    "\n",
    "### 1.1 Introduction\n",
    "- **Sklar's Theorem** states that any multivariate distribution can be represented in terms of its marginal distributions and a copula that captures the dependencies between them. Specifically:\n",
    "\n",
    "  If $ F $ is a joint cumulative distribution function (CDF) with marginals $ F_1, F_2, \\ldots, F_d $, then there exists a copula $ C$ such that\n",
    "\n",
    "   $$\n",
    "   F(x_1, x_2, \\ldots, x_d) = C(F_1(x_1), F_2(x_2), \\ldots, F_d(x_d))\n",
    "   $$\n",
    "\n",
    "   where $ F_i $ is the marginal CDF of the $ i $-th variable, and $ C $ is the **copula function** that describes the dependence structure between the variables.\n",
    "\n",
    "Conversely, any copula $ C $ with marginal distributions $ F_1, F_2, \\ldots, F_d $ can be used to construct a joint CDF $ F $ as given above.\n",
    "\n",
    "This theorem allows us to separate the modeling of marginal distributions from the modeling of dependencies, providing flexibility in statistical modeling and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gaussian Copula\n",
    "\n",
    "In practice, a copula function can be chosen from a wide variety of families, with the Gaussian copula being one of the most popular options. Among all copulas, the Gaussian copula is particularly favored due to its simplicity and effectiveness in capturing linear dependencies. In this context, we will use the Gaussian copula to estimate correlations.\n",
    "\n",
    "**Definition**: For the case where $ n = 2 $, the Gaussian copula models the dependence between two random variables $ X_1 $ and $ X_2 $. And the    Gaussian copula is defined as:\n",
    "$$\n",
    "C_\\text{Gauss}(u_1, u_2; \\rho) = \\Phi_\\rho(\\Phi^{-1}(u_1), \\Phi^{-1}(u_2)),\n",
    "$$\n",
    "where:\n",
    "\n",
    "- $ u_1 = F_{X_1}(x_1) $ and $ u_2 = F_{X_2}(x_2) $ are the marginal distributions (CDFs) of $ X_1 $ and $ X_2 $, respectively.\n",
    "- $ \\Phi^{-1} $ is the inverse of the standard normal CDF.\n",
    "- $ \\Phi_\\rho $ is the CDF of the bivariate normal distribution with correlation $ \\rho $.\n",
    "\n",
    "Here, we have copula function $C_\\text{Gauss}(u_1, u_2; \\rho)$, we can also write the copula density as:\n",
    "$$\n",
    "c_{\\text{Gauss}}(u_1, u_2; \\rho) = \\frac{\\exp\\left( -\\frac{1}{2(1 - \\rho^2)} \\left[ \\left( \\Phi^{-1}(u_1) \\right)^2 - 2 \\rho \\Phi^{-1}(u_1) \\Phi^{-1}(u_2) + \\left( \\Phi^{-1}(u_2) \\right)^2 \\right] \\right)}{2 \\pi \\sqrt{1 - \\rho^2}}\n",
    "$$\n",
    "Here, $\\rho$ is the only parameter in Gaussian copula. To obtain the value of $\\rho$, we will use Markov Chain Monte Carlo (MCMC) again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula_cdf_vector(u1, u2, rho):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian copula CDF for two variables with vector inputs.\n",
    "\n",
    "    Parameters:\n",
    "    u1 (array-like): The first marginal CDF values (0 < u1 < 1).\n",
    "    u2 (array-like): The second marginal CDF values (0 < u2 < 1).\n",
    "    rho (float): The correlation coefficient between the two variables (-1 < rho < 1).\n",
    "\n",
    "    Returns:\n",
    "    array: The values of the Gaussian copula CDF.\n",
    "    \"\"\"\n",
    "\n",
    "    u1 = np.asarray(u1)\n",
    "    u2 = np.asarray(u2)\n",
    "\n",
    "    z1 = stats.norm.ppf(u1)\n",
    "    z2 = stats.norm.ppf(u2)\n",
    "\n",
    "    z = np.vstack((z1, z2)).T\n",
    "\n",
    "    cov_matrix = [[1, rho], [rho, 1]]\n",
    "    \n",
    "    mvn_cdf = np.array([stats.multivariate_normal.cdf(z_i, mean=[0, 0], cov=cov_matrix) for z_i in z])\n",
    "    \n",
    "    return mvn_cdf\n",
    "\n",
    "# Example usage:\n",
    "u1 = [0.5, 0.3, 0.8]\n",
    "u2 = [0.7, 0.4, 0.9]\n",
    "rho = 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula_pdf_vector(u1, u2, rho):\n",
    "    '''Cauculate the Gaussian copula density value with given parameter'''\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, rho], [rho, 1]]\n",
    "    inv_u1 = norm.ppf(u1)\n",
    "    inv_u2 = norm.ppf(u2)\n",
    "\n",
    "    rv = multivariate_normal(mean, cov)\n",
    "    inv_uv = np.column_stack((inv_u1, inv_u2))\n",
    "\n",
    "    pdf_vals = rv.cdf(inv_uv)\n",
    "\n",
    "    return pdf_vals\n",
    "\n",
    "\n",
    "def log_copulas_val(u1, u2, rho):\n",
    "    return np.log(gaussian_copula_pdf_vector(u1, u2, rho))\n",
    "\n",
    "\n",
    "def conditional_gaussian_copula_vector(u1_vec, u2_vec, rho):\n",
    "    \"\"\"\n",
    "    Compute the conditional copula C(u1 | u2) for vectors of uniform variables using the Gaussian copula.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Conditional copula values C(u1 | u2) for each pair of (u1, u2).\n",
    "    \"\"\"\n",
    "    u1_vec = np.asarray(u1_vec)\n",
    "    u2_vec = np.asarray(u2_vec)\n",
    "\n",
    "    z1_vec = stats.norm.ppf(u1_vec)\n",
    "    z2_vec = stats.norm.ppf(u2_vec)\n",
    "\n",
    "    cond_cdf_vec = stats.norm.cdf(\n",
    "        (z1_vec - rho * z2_vec) / np.sqrt(1 - rho**2))\n",
    "    if cond_cdf_vec[441]==0:\n",
    "        print(z1_vec[441],u2_vec[441])\n",
    "    return cond_cdf_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discrete Copula\n",
    "According to the previous section, Sklar's theorem applies under the condition that all marginal distributions are continuous. However, this is not the case for our data, as we used binomial and ZINB models for simulation, both of which have discrete supports (integers). Therefore, we need to use a different approach to handle such discrete data. The method is from Smith, Michael & Khaled, Mohamad. (2011). Estimation of Copula Models With Discrete Margins via Bayesian Data Augmentation. Journal of the American Statistical Association. 107. 10.2139/ssrn.1937983. \n",
    "\n",
    "(Note that in this chapter, we focus solely on analyzing two datasets at a time.)\n",
    "\n",
    "### 2.1 Augmented Distribution\n",
    "We assume that the two marginal distributions are $X_1$, $X_2$, with $X=(X_1,X_2)$.\n",
    "Since the marginals for each dataset is discrete, let $a_i = F(x_i^-)$ be the left-hand limit of $F_i$ at $x_i$ and $b_i = F(x_i)$. In our model, we have just $a_i = F(x_i-1)$. Then the probability mass function of $X$ can be written in a closed term:\n",
    "$$\n",
    "f(\\boldsymbol{x}) = \\Delta_{a_1}^{b_1}\\Delta_{a_2}^{b_2}C(\\boldsymbol{v}),\n",
    "$$\n",
    "where $\\boldsymbol{v}=(v_1,v_2)$, and the operator here is the difference notation of Nelsen(2006). Expand the right-hand side we get:\n",
    "\\begin{equation}\n",
    "f(\\boldsymbol{x}) = C(b_1,b_2)+C(a_1,a_2)-C(b_1,a_2)-C(a_1,b_2).\n",
    "\\end{equation}\n",
    "The following code uses the fitted parameters to compute all the values of $a_i$ and $b_i$ for each entry in our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(data, para):\n",
    "    N = data.shape[0]\n",
    "    data_range = pd.DataFrame(index=range(N), columns=data.columns.to_list())\n",
    "    for col in data.columns:\n",
    "        para_0 = para[col]\n",
    "        if not pd.isna(para_0[2]):\n",
    "            for i in range(N):\n",
    "                x = data_pro[col][i]\n",
    "                data_range.loc[i, col] = [x, tl.zinb_cdf(\n",
    "                    x-1, para_0), tl.zinb_cdf(x, para_0)]\n",
    "        else:\n",
    "            for i in range(N):\n",
    "                x = data_pro[col][i]\n",
    "                data_range.loc[i, col] = [x, stats.nbinom.cdf(\n",
    "                    x-1, para_0[0], para_0[1]), stats.nbinom.cdf(x, para_0[0], para_0[1])]\n",
    "    return data_range\n",
    "\n",
    "\n",
    "data_range = get_range(data_pro, fitted_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry now is a list consists three elements, where the first one is the original entry $x_{ij}$ $(i = 1,2,\\dots,13,\\ j = 1,2,\\dots,N)$ where $N$ is the number of observations. And it is followed by the corresponding values of $a_{ij}$ and $b_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this discrete copula model, we consider a joint distribution of $(X,U)$, with $U=(U_1,U_2)$ where each $U_i$ a uniform distribution on $[0,1]$\n",
    "- Proposition: If $(X, U)$ has mixed probability density given by:\n",
    "  $$\n",
    "  f(\\boldsymbol{x},\\boldsymbol{u}) = f(\\boldsymbol{x}|\\boldsymbol{u})f(\\boldsymbol{u})=\\prod_{j=1}^{m} \\mathbb{I}(F_j(x_j^-) \\leq u_j < F_j(x_j)) c(\\boldsymbol{u}),\n",
    "\\end{equation}\n",
    "  where $ f(\\mathbf{x}|\\mathbf{u}) = \\prod_{j=1}^{m} f(x_j | u_j)$, then the marginal probability mass function of $X$ is given by equation $(1)$.\n",
    "\n",
    "In our case, we have $m=2$.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\rho$ be the copula parameter, then we can write the mixed PDF as:\n",
    "$$\n",
    "f(\\boldsymbol{x},\\boldsymbol{u}|\\rho) = \\prod_{i=1}^{n}  c(\\boldsymbol{u_i};\\rho) \\prod_{j=1}^{m=2} \\mathbb{I}(a_{ij} \\leq u_{ij} < b_{ij}),\n",
    "$$\n",
    "where $n$ is the number of observations, $\\boldsymbol{u}=(u_1,u_2,\\dots,u_n)$ and $\\boldsymbol{u_i} = (u_{i1},u_{i2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sampling Schemes\n",
    "We then use MCMC to estimate the values of $\\rho$ and $\\boldsymbol{u}$. First we need to know the necessary conditional probabilities.\n",
    "\n",
    "\n",
    "- **Sample $\\boldsymbol{u}$**\n",
    "    \n",
    "    Here, we sample $\\boldsymbol{u}$ each margin at a time. And we have for $j = 1, 2$:\n",
    "    $$\n",
    "    f(\\boldsymbol{u}_j|\\rho,\\boldsymbol{x},\\boldsymbol{u}_{k\\neq j})\\propto \\prod_{i=1}^{n} \\mathbb{I}(a_{ij} \\leq u_{ij} < b_{ij})c_{j|k\\neq j}(u_{ij}|u_{ik,k\\neq j},\\rho)\\tag{2}\n",
    "    $$\n",
    "    Therefore, according to equation $(2)$, the latents $u_{ij}$ are generated from the conditional densities $c_{j|k\\neq j}$ constrained to $[a_{ij} , b_{ij})$, and an iterate for $\\boldsymbol{u_j}$ obtained.\n",
    "\n",
    "    So first, we set the initial values for $\\boldsymbol{u}$ with the constrained range for each entry $u_{ij}$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial(data):\n",
    "    '''Set the initial values for matrix u\n",
    "    Input:\n",
    "    Dataframe with each entry be a list of length 3, ordered [x_ij, a_ij, b_ij]\n",
    "\n",
    "    Return:\n",
    "    Dataframe with each entry be a list of length 3, ordered [u_ij, a_ij, b_ij]\n",
    "    '''\n",
    "    N = data.shape[0]\n",
    "    data_initial = pd.DataFrame(index=range(N), columns=data.columns.to_list())\n",
    "    for col in data.columns:\n",
    "        for i in range(N):\n",
    "            data_initial.loc[i, col] = [random.uniform(\n",
    "                data[col][i][1], data[col][i][2])]\n",
    "            data_initial.loc[i, col] += data[col][i][1:]\n",
    "    return data_initial\n",
    "\n",
    "\n",
    "initial_u = set_initial(data_range)\n",
    "initial_u.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $u$, we know exactly how to sample a new value for $u$ with given $\\rho$, so for $u$, we perform MH algorithm here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_u(u, ranges, rho):\n",
    "    '''Get the proposal value for u with given constraint range'''\n",
    "    u = np.asarray(u)\n",
    "\n",
    "    # Compute inverse CDF (norm.ppf) for u\n",
    "    inv2 = norm.ppf(u)\n",
    "    N = u.shape[0]\n",
    "    # Extract lower and upper bounds from the ranges matrix\n",
    "    a = [lis[0] for lis in ranges]\n",
    "    b = [lis[1] for lis in ranges]\n",
    "\n",
    "    u_0 = np.random.uniform(size=N)\n",
    "    cdf_low = conditional_gaussian_copula_vector(a, u, rho)\n",
    "    cdf_upper = conditional_gaussian_copula_vector(b, u, rho)\n",
    "\n",
    "    u2 = norm.cdf(norm.ppf((cdf_upper-cdf_low)*u_0+cdf_low)\n",
    "                  * np.sqrt(1-rho**2)+rho*inv2)\n",
    "    # last term converges to zero\n",
    "    print(a[441], b[441], u2[441], ((cdf_upper-cdf_low)*u_0+cdf_low)[441])\n",
    "    return u2\n",
    "\n",
    "\n",
    "# sample_u([0.5, 0.4], [[0.6, 0.7], [0.2, 0.8]], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_gaussian_copula_pdf(u1,u2,rho):\n",
    "    '''Calculate the value of c(u1|u2;rho)'''\n",
    "    return norm.pdf(u1,loc = rho*u2,scale = np.sqrt(1-rho^2))\n",
    "\n",
    "def conditional_pdf_u(u_0,u,range_u,i,rho):\n",
    "    if u_0>=range_u[0] and u_0 < range_u[1]:\n",
    "        return conditional_gaussian_copula_pdf(u,u_0,rho)/(conditional_gaussian_copula_vector(range_u[1],u,rho)-conditional_gaussian_copula_vector(range_u[0],u,rho))\n",
    "    return 0\n",
    "\n",
    "def proposal_distribution(size=1):\n",
    "    return np.random.exponential(1, size) \n",
    "\n",
    "def rejection_sampling_u(u_0,u, M,rho):       \n",
    "    u_p = u\n",
    "    N = u.shape[0]\n",
    "    col = u.columns\n",
    "        \n",
    "    u_condition = [u[col[0]][i][0] for i in range(N)]\n",
    "    u_0_ranges = [u_0[u_0.columns[0]][i][1:] for i in range(N)]\n",
    "    #  Draw uniform random variable\n",
    "    \n",
    "    for i  in len(u):\n",
    "        x_proposed = proposal_distribution()\n",
    "        alpha = np.random.uniform(0, 1)\n",
    "    #  Accept or reject the sample\n",
    "        while alpha > conditional_pdf_u(x_proposed,u_condition[i],u_0_ranges[i],i,rho) / (M * np.exp(-u_p)): \n",
    "            x_proposed = proposal_distribution()\n",
    "            alpha = np.random.uniform(0, 1) # p(x) / (M * q(x))\n",
    "        u_p[i][0] = x_proposed\n",
    "    return u_p\n",
    "def get_alpha(u1_p,u1,u2_range,rho):\n",
    "    term1 = conditional_gaussian_copula_vector(u2_range[1],u1_p,rho)-conditional_gaussian_copula_vector(u2_range[1],u1_p,rho)\n",
    "    term2 = conditional_gaussian_copula_vector(u2_range[1],u1,rho)-conditional_gaussian_copula_vector(u2_range[1],u1,rho)\n",
    "    return term1/term2\n",
    "def mh_prop_u(u1_pack,u2_pack,rho):\n",
    "    N = u1_pack.shape[0]\n",
    "    u1= [u1_pack[u1_pack.columns[0]][i][0] for i in range(N)]\n",
    "    u2_ranges = [u2_pack[u2_pack.columns[0]][i][1:] for i in range(N)]\n",
    "    u1_p = set_initial(u1)\n",
    "    u2_p = rejection_sampling_u(u1, 1.0,rho)\n",
    "    alpha = [get_alpha(u1_p[i],u1[i],u2_ranges[i],rho) for i in range(N)]\n",
    "    for i,val in enumerate(alpha):\n",
    "     \n",
    "        u = np.random.uniform(0, 1)\n",
    "        if u <= min(1,val):\n",
    "            u1[i] = u1_p[i]\n",
    "            u2[i] = u2_p[i]\n",
    "    return u1,u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_u(u1_pack, u2_pack, rho):\n",
    "    '''propose new u_2 given the values form other'''\n",
    "    N = u1_pack.shape[0]\n",
    "    col2 = u2_pack.columns\n",
    "    u1_condition = [u1_pack[u1_pack.columns[0]][i][0] for i in range(N)]\n",
    "    u2_ranges = [u2_pack[col2[0]][i][1:] for i in range(N)]\n",
    "\n",
    "    u2 = pd.DataFrame(index=range(N), columns=col2.to_list())\n",
    "\n",
    "    new_val = sample_u(u1_condition, u2_ranges, rho)\n",
    "    \n",
    "    u2[col2[0]] = [[new_val[i], u2_pack[col2[0]][i][1], u2_pack[col2[0]][i][2]]\n",
    "                   for i in range(N)]\n",
    "    #print(u2[col2[0]][441])\n",
    "    return u2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Propose $\\boldsymbol{\\rho}$**\n",
    "$$\n",
    "f(\\rho|\\boldsymbol{u},\\boldsymbol{x}) = f(\\rho|\\boldsymbol{u}) \\propto \\prod_{i=1}^{n} c(\\boldsymbol{u_i};\\rho)\\pi(\\rho)\\tag{3}\n",
    "$$\n",
    "Here, $\\pi(\\rho)$ is the prior, and we choose the prior to be the truncated normal distribution between $-1$ and $1$ with standard deviation $\\sigma_\\rho$. So we have the proprosal algorithm for $\\rho$ as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncnorm_prop_rho(x, sigma):  # proposal for rho \n",
    "    return truncnorm.rvs((-1-x) / sigma, (1-x) / sigma, loc=x, scale=sigma)\n",
    "\n",
    "def truncnorm_rho_pdf(x, x_p, sigma):\n",
    "    rv = truncnorm((-1-x) / sigma, (1-x) / sigma, loc=x, scale=sigma)\n",
    "    return rv.pdf(x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the log acceptance ratio for the proposal $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_acceptance_ratio(u, para):\n",
    "    rho, rho_p = para\n",
    "    u1, u2 = u\n",
    "\n",
    "    u1 = u1.to_numpy()\n",
    "    u2 = u2.to_numpy()\n",
    "    \n",
    "    u1 = [li[0][0] for li in u1]\n",
    "    u2 = [li[0][0] for li in u2]\n",
    "\n",
    "    acc = sum(log_copulas_val(u1, u2, rho_p)) - \\\n",
    "        sum(log_copulas_val(u1, u2, rho))\n",
    "        \n",
    "    return acc\n",
    "# gc_acceptance_ratio(initial_u[['MT-CO1']],initial_u[['MT-CO2']],(0.4,0.5),0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_marginal(num, r, p, u_raw):\n",
    "\n",
    "    N, J = num.shape\n",
    "\n",
    "    rtn = [np.zeros((N, J)), np.zeros((N, J))]\n",
    "\n",
    "    for j in range(J):\n",
    "        for n in range(N):\n",
    "\n",
    "            Ubound = nbinom.cdf(num[n, j], r[j], p[j])\n",
    "            Lbound = 0\n",
    "            if num[n, j] > 0:\n",
    "                Lbound = nbinom.cdf(num[n, j] - 1, r[j], p[j])\n",
    "            UmL = Ubound - Lbound\n",
    "            rtn[0][n, j] = norm.ppf(Lbound + UmL * u_raw[n, j])\n",
    "            rtn[1][n, j] = np.log(UmL)\n",
    "\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def apply_ng_marginal(name1, name2, u):\n",
    "    num = data_pro[[name1, name2]].values\n",
    "    r = fitted_para.loc[0, [name1, name2]].values\n",
    "    p = fitted_para.loc[1, [name1, name2]].values\n",
    "    u_raw = u\n",
    "    return nb_marginal(num, r, p, u_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_gc(u1, u2, sigma, n_iter=10000, burn_in=2000, thin=5):\n",
    "\n",
    "    trace = np.zeros(n_iter)\n",
    "    trace[0] = 0.5\n",
    "\n",
    "    acceptance_rate = np.zeros(n_iter)\n",
    "    rho = trace[0]\n",
    "\n",
    "    for i in range(1, n_iter):\n",
    "        rho = trace[i-1]\n",
    "        rho_p = truncnorm_prop_rho(rho, sigma)\n",
    "\n",
    "\n",
    "        # Metropolis algorithm to rho\n",
    "        alpha = gc_acceptance_ratio((u1, u2), (rho, rho_p))\n",
    "        u = np.log(np.random.uniform(0., 1.))\n",
    "\n",
    "        if u < alpha:\n",
    "            trace[i] = rho_p\n",
    "            acceptance_rate[i-1] = 1\n",
    "\n",
    "        else:\n",
    "            trace[i] = rho\n",
    "    print(u1.columns[0]+' and '+u2.columns[0] +\n",
    "          \" acceptance rate is: %.2f\" % acceptance_rate[burn_in:].mean())\n",
    "    return pd.DataFrame(trace[burn_in::thin])\n",
    "\n",
    "\n",
    "def metropolis_hastings_para(u1, u2, sigma, n_iter=10000, burn_in=2000, thin=5):\n",
    "    trace = np.zeros(n_iter)\n",
    "    trace[0] = [0.5,u1,u2]\n",
    "\n",
    "    acceptance_rate = np.zeros(n_iter)\n",
    "    rho = trace[0]\n",
    "    u1 = trace[1]\n",
    "    u2 = trace[2]\n",
    "\n",
    "    for i in range(1, n_iter):\n",
    "        rho = trace[i-1]\n",
    "        rho_p = truncnorm_prop_rho(rho, sigma)\n",
    "        u1_p ,u2_p = mh_prop_u(u1,u2,rho)\n",
    "\n",
    "        # Metropolis algorithm to u\n",
    "        alpha_u = update_u((u1, u2),(u1_p,u2_p) rho)\n",
    "        u = np.log(np.random.uniform(0., 1.))\n",
    "\n",
    "        # Metropolis algorithm to rho\n",
    "        alpha_rho = gc_acceptance_ratio((u1, u2), (rho, rho_p))\n",
    "        u = np.log(np.random.uniform(0., 1.))\n",
    "\n",
    "        if u < alpha_u:\n",
    "            trace[i][0] = rho_p\n",
    "            \n",
    "        else:\n",
    "            trace[i] = rho\n",
    "    print(u1.columns[0]+' and '+u2.columns[0] +\n",
    "          \" acceptance rate is: %.2f\" % acceptance_rate[burn_in:].mean())\n",
    "    return pd.DataFrame(trace[burn_in::thin])\n",
    "\n",
    "trace_0 = metropolis_hastings_gc(\n",
    "    initial_u[['MT-CO2']], initial_u[['MT-CO3']], sigma=0.01, n_iter=200, burn_in=0, thin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trace_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_o = np.zeros((13,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data_range.columns.to_list()\n",
    "traces = pd.DataFrame(index=names, columns=names)\n",
    "\n",
    "for i in range(13):\n",
    "    for j in range(i+1, 13):\n",
    "        if cor_o[i, j] == 0 or cor_o[i, j] == 0.5:\n",
    "            tra = metropolis_hastings_gc(initial_u[[names[i]]], initial_u[[\n",
    "                                         names[j]]], sigma=0.01, n_iter=5000, burn_in=1000, thin=5)\n",
    "            traces.loc[names[i], names[j]] = [\n",
    "                tra[:100].mean()-tra[-100:].mean(), tra, tra.mean()]\n",
    "            cor_o[i, j] = float(tra.mean().iloc[0])\n",
    "            print(cor_o[i, j])\n",
    "    print(cor_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cor_o, columns=names,index=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the Correlatioon\n",
    "\n",
    "After doing the MCMC, we obatin the convergence values for $u$ and $\\rho$. Then, we calciulate the value of kendalls tau using the value of $\\rho$, where tau can be written as:\n",
    "$$\n",
    "\\tau_{i,j}^{F}( \\Theta) = \\sum_{x_i} \\sum_{x_j} f_{i,j}(x_i, x_j; \\Theta) \\Big[C_{i,j}(F_i, F_j) \n",
    "+ C_{i,j}(F_i, \\bar{F}_j) + C_{i,j}(\\bar{F}_i, F_j) \n",
    "+ C_{i,j}(\\bar{F}_i, \\bar{F}_j) \\Big] - 1,\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data_pro.columns.to_list()\n",
    "\n",
    "def kendalls_tau(name1, name2):\n",
    "    tau = 0\n",
    "\n",
    "    rho = 0.9# cor_o[pos1, pos2]\n",
    "    x1 = data_range[name1]\n",
    "    x2 = data_range[name2]\n",
    "\n",
    "    for val1 in x1:\n",
    "\n",
    "        for val2 in x2:\n",
    "            f = sum(gaussian_copula_pdf_vector([val1[2], val1[1]], [val2[2], val2[1]], rho))-sum(gaussian_copula_pdf_vector([val1[1], val1[2]],\n",
    "                                                                                                                            [val2[2], val2[1]], rho))\n",
    "            term2 = sum(gaussian_copula_pdf_vector([val1[2], val1[1], val1[2], val1[1]], [\n",
    "                val2[2], val2[1], val2[1], val2[2]], rho))\n",
    "            tau += f*term2\n",
    "        print(tau)\n",
    "    tau -= 1\n",
    "    return tau\n",
    "# the value for f is too small, guess it is the reason tau is so close to zero with any value of rho.\n",
    "\n",
    "kendalls_tau('MT-CO1', 'MT-CO2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !\n",
    " Cannot get a resonable output when calculate kendalls tau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
